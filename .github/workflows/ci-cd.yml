name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: patient-web-interface

jobs:
  test:
    runs-on: ubuntu-latest
    name: Test and Lint
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        cd project
        pip install -r requirements.txt
        pip install pytest pytest-cov
        
    - name: Run linting with flake8
      run: |
        cd project
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Run tests with pytest
      run: |
        cd project
        pytest test_app.py -v --cov=main --cov-report=xml --cov-report=term-missing
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./project/coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  security:
    runs-on: ubuntu-latest
    name: Security Scan
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install security tools
      run: pip install pip-audit
      
    - name: Run security scan
      run: |
        cd project
        pip-audit -r requirements.txt || echo "Security scan completed with warnings"

  build:
    runs-on: ubuntu-latest
    name: Build Docker Image
    needs: [test, security]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Login to GitHub Container Registry
      if: github.event_name != 'pull_request'
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
          
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./project
        file: ./project/Dockerfile
        platforms: linux/amd64,linux/arm64
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Debug image information
      if: github.event_name != 'pull_request'
      run: |
        echo "Repository: ${{ github.repository }}"
        echo "Repository owner: ${{ github.repository_owner }}"
        echo "Registry: ${{ env.REGISTRY }}"
        echo "Image name: ${{ env.IMAGE_NAME }}"
        echo "Expected image: ${{ env.REGISTRY }}/${{ github.repository }}:latest"
        echo "Generated tags: ${{ steps.meta.outputs.tags }}"
        
        # Extract the first tag (which should be the latest tag)
        FIRST_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n1)
        echo "TRIVY_IMAGE_REF=$FIRST_TAG" >> $GITHUB_ENV
        
    - name: Run Trivy vulnerability scanner
      if: github.event_name != 'pull_request'
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.TRIVY_IMAGE_REF }}
        format: 'sarif'
        output: 'trivy-results.sarif'
        exit-code: '0'  # Don't fail the build on vulnerabilities, just report them
        
    - name: Upload Trivy scan results to GitHub Security tab
      if: github.event_name != 'pull_request'
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  deploy-staging:
    runs-on: ubuntu-latest
    name: Deploy to Staging
    needs: build
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add your staging deployment commands here
        # For example, updating a staging server or cloud service
        
  deploy-production:
    runs-on: ubuntu-latest
    name: Deploy to Kubernetes (Minikube)
    needs: build
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
      
    - name: Start Minikube
      uses: medyagh/setup-minikube@master
      with:
        driver: docker
        memory: 2048
        cpus: 2
      
    - name: Enable Minikube addons
      run: |
        minikube addons enable ingress
        minikube addons enable metrics-server
        minikube addons enable dashboard
        
        # Wait for ingress controller to be ready
        echo "â³ Waiting for NGINX Ingress Controller to be ready..."
        kubectl wait --namespace ingress-nginx \
          --for=condition=ready pod \
          --selector=app.kubernetes.io/component=controller \
          --timeout=300s
        
        # Verify ingress controller webhook
        kubectl get validatingwebhookconfiguration -o name | grep ingress || echo "No ingress webhook found"
    
    - name: Verify Minikube
      run: |
        minikube status
        kubectl cluster-info
        kubectl get nodes
      
    - name: Deploy to Kubernetes
      run: |
        cd k8s
        
        echo "ğŸ“¦ Applying Kubernetes manifests..."
        kubectl apply -f deployment.yaml
        
        # Apply ingress with error handling
        echo "ğŸŒ Applying Ingress configuration..."
        if kubectl apply -f ingress-simple.yaml; then
          echo "âœ… Ingress applied successfully"
        elif kubectl apply -f ingress.yaml; then
          echo "âœ… Full ingress applied successfully"
        else
          echo "âš ï¸ Ingress application failed, continuing without ingress..."
          echo "This is common in CI environments. Application will still be accessible via port-forward or NodePort."
        fi
        
        # Apply monitoring resources with error handling
        echo "ğŸ“Š Applying monitoring configuration..."
        if kubectl apply -f monitoring-ci.yaml; then
          echo "âœ… CI monitoring resources applied successfully"
        elif kubectl apply -f monitoring.yaml; then
          echo "âœ… Full monitoring resources applied successfully"
        else
          echo "âš ï¸ Monitoring application failed, continuing without monitoring..."
          echo "This is common in CI environments without Prometheus Operator."
        fi
        
        echo "â³ Waiting for deployment to be ready..."
        kubectl wait --for=condition=available --timeout=300s deployment/patient-web-interface -n patient-web-interface
        
        echo "ğŸ“Š Verifying deployment..."
        kubectl get pods -n patient-web-interface
        kubectl get services -n patient-web-interface
        kubectl get ingress -n patient-web-interface 2>/dev/null || echo "No ingress resources found"
      
    - name: Test Kubernetes deployment
      run: |
        echo "ğŸ§ª Testing application accessibility..."
        
        # Get pod status first
        kubectl get pods -n patient-web-interface -l app=patient-web-interface
        
        # Check if pods are running
        if kubectl wait --for=condition=ready pod -l app=patient-web-interface -n patient-web-interface --timeout=60s; then
          echo "âœ… Pods are ready!"
          
          # Set up port forwarding in background
          kubectl port-forward service/patient-web-interface-service 8080:80 -n patient-web-interface &
          PF_PID=$!
          
          # Wait for port forwarding to be ready
          sleep 15
          
          # Test if application is responding
          if curl -f --max-time 30 http://localhost:8080; then
            echo "âœ… Application is accessible via port forwarding!"
          else
            echo "âŒ Application is not accessible, checking logs..."
            kubectl logs -l app=patient-web-interface -n patient-web-interface --tail=50
          fi
          
          # Clean up port forwarding
          kill $PF_PID 2>/dev/null || true
        else
          echo "âŒ Pods are not ready, checking logs..."
          kubectl describe pods -l app=patient-web-interface -n patient-web-interface
          kubectl logs -l app=patient-web-interface -n patient-web-interface --tail=50
        fi
      
    - name: Get deployment information
      run: |
        echo "ğŸ“‹ Deployment Summary:"
        kubectl get all -n patient-web-interface
        
        echo ""
        echo "ğŸŒ Access Information:"
        echo "â€¢ Port Forward: kubectl port-forward service/patient-web-interface-service 8080:80 -n patient-web-interface"
        echo "â€¢ Minikube Service: minikube service patient-web-interface-service -n patient-web-interface"
        echo "â€¢ Dashboard: minikube dashboard"
        
        echo ""
        echo "ğŸ“Š Resource Usage:"
        kubectl top pods -n patient-web-interface || echo "Metrics not available yet"
        
        echo ""
        echo "ğŸ” HPA Status:"
        kubectl get hpa -n patient-web-interface

  notification:
    runs-on: ubuntu-latest
    name: Notify Deployment Status
    needs: [test, security, build, deploy-production]
    if: always()
    
    steps:
    - name: Notify deployment status
      if: github.event_name != 'pull_request'
      run: |
        echo "ğŸ“Š CI/CD Pipeline Results:"
        echo "â€¢ Tests: ${{ needs.test.result }}"
        echo "â€¢ Security: ${{ needs.security.result }}"
        echo "â€¢ Build: ${{ needs.build.result }}"
        echo "â€¢ Kubernetes Deploy: ${{ needs.deploy-production.result }}"
        
        if [ "${{ needs.test.result }}" = "success" ] && [ "${{ needs.security.result }}" = "success" ] && [ "${{ needs.build.result }}" = "success" ] && [ "${{ needs.deploy-production.result }}" = "success" ]; then
          echo ""
          echo "ğŸ‰ SUCCESS: All jobs completed successfully!"
          echo "âœ… Application deployed to Kubernetes (Minikube)"
          echo "ğŸŒ Access via: kubectl port-forward service/patient-web-interface-service 8080:80 -n patient-web-interface"
        else
          echo ""
          echo "âŒ FAILURE: Some jobs failed. Check the logs for details."
          echo "ğŸ“‹ Failed jobs:"
          [ "${{ needs.test.result }}" != "success" ] && echo "  â€¢ Tests"
          [ "${{ needs.security.result }}" != "success" ] && echo "  â€¢ Security scan"
          [ "${{ needs.build.result }}" != "success" ] && echo "  â€¢ Docker build"
          [ "${{ needs.deploy-production.result }}" != "success" ] && echo "  â€¢ Kubernetes deployment"
          exit 1
        fi
