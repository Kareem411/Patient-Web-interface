name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: patient-web-interface

jobs:
  test:
    runs-on: ubuntu-latest
    name: Test and Lint
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        cd project
        pip install -r requirements.txt
        pip install pytest pytest-cov
        
    - name: Run linting with flake8
      run: |
        cd project
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Run tests with pytest
      run: |
        cd project
        pytest test_app.py -v --cov=main --cov-report=xml --cov-report=term-missing
        
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./project/coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  security:
    runs-on: ubuntu-latest
    name: Security Scan
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install security tools
      run: pip install pip-audit
      
    - name: Run security scan
      run: |
        cd project
        pip-audit -r requirements.txt || echo "Security scan completed with warnings"

  build:
    runs-on: ubuntu-latest
    name: Build Docker Image
    needs: [test, security]
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Login to GitHub Container Registry
      if: github.event_name != 'pull_request'
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
        
    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ github.repository }}
        tags: |
          type=ref,event=branch
          type=ref,event=pr
          type=sha,prefix={{branch}}-
          type=raw,value=latest,enable={{is_default_branch}}
          
    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: ./project
        file: ./project/Dockerfile
        platforms: linux/amd64,linux/arm64
        push: ${{ github.event_name != 'pull_request' }}
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
        
    - name: Debug image information
      if: github.event_name != 'pull_request'
      run: |
        echo "Repository: ${{ github.repository }}"
        echo "Repository owner: ${{ github.repository_owner }}"
        echo "Registry: ${{ env.REGISTRY }}"
        echo "Image name: ${{ env.IMAGE_NAME }}"
        echo "Expected image: ${{ env.REGISTRY }}/${{ github.repository }}:latest"
        echo "Generated tags: ${{ steps.meta.outputs.tags }}"
        
        # Extract the first tag (which should be the latest tag)
        FIRST_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n1)
        echo "TRIVY_IMAGE_REF=$FIRST_TAG" >> $GITHUB_ENV
        
    - name: Run Trivy vulnerability scanner
      if: github.event_name != 'pull_request'
      uses: aquasecurity/trivy-action@master
      with:
        image-ref: ${{ env.TRIVY_IMAGE_REF }}
        format: 'sarif'
        output: 'trivy-results.sarif'
        exit-code: '0'  # Don't fail the build on vulnerabilities, just report them
        
    - name: Upload Trivy scan results to GitHub Security tab
      if: github.event_name != 'pull_request'
      uses: github/codeql-action/upload-sarif@v2
      with:
        sarif_file: 'trivy-results.sarif'

  deploy-staging:
    runs-on: ubuntu-latest
    name: Deploy to Staging
    needs: build
    if: github.ref == 'refs/heads/develop'
    environment: staging
    
    steps:
    - name: Deploy to staging
      run: |
        echo "Deploying to staging environment..."
        # Add your staging deployment commands here
        # For example, updating a staging server or cloud service
        
  deploy-production:
    runs-on: ubuntu-latest
    name: Deploy to Kubernetes (Minikube)
    needs: build
    if: github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'latest'
      
    - name: Login to GitHub Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}
      
    - name: Start Minikube
      uses: medyagh/setup-minikube@master
      with:
        driver: docker
        memory: 2048
        cpus: 2
      
    - name: Enable Minikube addons
      run: |
        minikube addons enable ingress
        minikube addons enable metrics-server
        minikube addons enable dashboard
        
        # Wait for ingress controller to be ready
        echo "Waiting for NGINX Ingress Controller to be ready..."
        kubectl wait --namespace ingress-nginx \
          --for=condition=ready pod \
          --selector=app.kubernetes.io/component=controller \
          --timeout=300s
        
        # Verify ingress controller webhook
        kubectl get validatingwebhookconfiguration -o name | grep ingress || echo "No ingress webhook found"
    
    - name: Verify Minikube
      run: |
        minikube status
        kubectl cluster-info
        kubectl get nodes
    
    - name: Create image pull secret
      run: |
        echo "Creating image pull secret for private registry access..."
        kubectl create namespace patient-web-interface --dry-run=client -o yaml | kubectl apply -f -
        kubectl create secret docker-registry ghcr-secret \
          --docker-server=ghcr.io \
          --docker-username=${{ github.actor }} \
          --docker-password=${{ secrets.GITHUB_TOKEN }} \
          --docker-email=${{ github.actor }}@users.noreply.github.com \
          -n patient-web-interface --dry-run=client -o yaml | kubectl apply -f -
      
    - name: Deploy to Kubernetes
      run: |
        cd k8s
        
        echo "Checking if image is accessible..."
        echo "Expected image: ghcr.io/kareem411/patient-web-interface:latest"
        
        # Try to pull the image to verify it's accessible
        if docker pull ghcr.io/kareem411/patient-web-interface:latest; then
          echo "Image is accessible and pulled successfully"
        else
          echo "Failed to pull image from registry"
          echo "Available images in the registry:"
          echo "This might be due to the image not being public or authentication issues"
        fi
        
        echo "Applying Kubernetes manifests (CI version)..."
        kubectl apply -f deployment-ci.yaml
        
        # Apply ingress with error handling
        echo "Applying Ingress configuration..."
        if kubectl apply -f ingress-simple.yaml; then
          echo "Ingress applied successfully"
        elif kubectl apply -f ingress.yaml; then
          echo "Full ingress applied successfully"
        else
          echo "Ingress application failed, continuing without ingress..."
          echo "This is common in CI environments. Application will still be accessible via port-forward or NodePort."
        fi
        
        # Apply monitoring resources with error handling
        echo "Applying monitoring configuration..."
        if kubectl apply -f monitoring-ci.yaml; then
          echo "CI monitoring resources applied successfully"
        elif kubectl apply -f monitoring.yaml; then
          echo "Full monitoring resources applied successfully"
        else
          echo "Monitoring application failed, continuing without monitoring..."
          echo "This is common in CI environments without Prometheus Operator."
        fi
        
        echo "Waiting for deployment to be ready..."
        kubectl wait --for=condition=available --timeout=600s deployment/patient-web-interface -n patient-web-interface
        
        echo "Verifying deployment..."
        kubectl get pods -n patient-web-interface
        kubectl get services -n patient-web-interface
        kubectl get ingress -n patient-web-interface 2>/dev/null || echo "No ingress resources found"
      
    - name: Test Kubernetes deployment
      run: |
        echo "Testing application accessibility..."
        
        # Get detailed pod status first
        echo "Current pod status:"
        kubectl get pods -n patient-web-interface -l app=patient-web-interface -o wide
        
        echo "Pod descriptions:"
        kubectl describe pods -l app=patient-web-interface -n patient-web-interface
        
        # Check events for any issues
        echo "Recent events:"
        kubectl get events -n patient-web-interface --sort-by='.firstTimestamp' | tail -20
        
        # Check if pods are running
        if kubectl wait --for=condition=ready pod -l app=patient-web-interface -n patient-web-interface --timeout=120s; then
          echo "Pods are ready!"
          
          # Show pod logs before testing
          echo "Pod logs:"
          kubectl logs -l app=patient-web-interface -n patient-web-interface --tail=20
          
          # Set up port forwarding in background
          kubectl port-forward service/patient-web-interface-service 8080:80 -n patient-web-interface &
          PF_PID=$!
          
          # Wait for port forwarding to be ready
          sleep 20
          
          # Test if application is responding
          echo "Testing application response..."
          if curl -f --max-time 30 -v http://localhost:8080; then
            echo "Application is accessible via port forwarding!"
            
            # Test the health endpoint
            if curl -f --max-time 30 http://localhost:8080/health; then
              echo "Health endpoint is working!"
            else
              echo "Health endpoint failed, but main page works"
            fi
          else
            echo "Application is not accessible, checking logs..."
            kubectl logs -l app=patient-web-interface -n patient-web-interface --tail=50
            
            echo "Service endpoints:"
            kubectl get endpoints -n patient-web-interface
            
            echo "Service details:"
            kubectl describe service/patient-web-interface-service -n patient-web-interface
          fi
          
          # Clean up port forwarding
          kill $PF_PID 2>/dev/null || true
        else
          echo "Pods are not ready, checking detailed status..."
          
          echo "Pod status:"
          kubectl get pods -l app=patient-web-interface -n patient-web-interface -o yaml
          
          echo "Pod logs:"
          kubectl logs -l app=patient-web-interface -n patient-web-interface --tail=100
          
          echo "Image pull status:"
          kubectl describe pods -l app=patient-web-interface -n patient-web-interface | grep -A 10 -B 5 "Image"
          
          # Try to debug image pull issues
          echo "Checking image pull secrets:"
          kubectl get pods -l app=patient-web-interface -n patient-web-interface -o jsonpath='{.items[*].spec.imagePullSecrets}'
          
          exit 1
        fi
      
    - name: Get deployment information
      run: |
        echo "Deployment Summary:"
        kubectl get all -n patient-web-interface
        
        echo ""
        echo "Access Information:"
        echo "• Port Forward: kubectl port-forward service/patient-web-interface-service 8080:80 -n patient-web-interface"
        echo "• Minikube Service: minikube service patient-web-interface-service -n patient-web-interface"
        echo "• Dashboard: minikube dashboard"
        
        echo ""
        echo "Resource Usage:"
        kubectl top pods -n patient-web-interface || echo "Metrics not available yet"
        
        echo ""
        echo "HPA Status:"
        kubectl get hpa -n patient-web-interface

  notification:
    runs-on: ubuntu-latest
    name: Notify Deployment Status
    needs: [test, security, build, deploy-production]
    if: always()
    
    steps:
    - name: Notify deployment status
      if: github.event_name != 'pull_request'
      run: |
        echo "CI/CD Pipeline Results:"
        echo "• Tests: ${{ needs.test.result }}"
        echo "• Security: ${{ needs.security.result }}"
        echo "• Build: ${{ needs.build.result }}"
        echo "• Kubernetes Deploy: ${{ needs.deploy-production.result }}"
        
        if [ "${{ needs.test.result }}" = "success" ] && [ "${{ needs.security.result }}" = "success" ] && [ "${{ needs.build.result }}" = "success" ] && [ "${{ needs.deploy-production.result }}" = "success" ]; then
          echo ""
          echo "SUCCESS: All jobs completed successfully!"
          echo "Application deployed to Kubernetes (Minikube)"
          echo "Access via: kubectl port-forward service/patient-web-interface-service 8080:80 -n patient-web-interface"
        else
          echo ""
          echo "FAILURE: Some jobs failed. Check the logs for details."
          echo "Failed jobs:"
          [ "${{ needs.test.result }}" != "success" ] && echo "  • Tests"
          [ "${{ needs.security.result }}" != "success" ] && echo "  • Security scan"
          [ "${{ needs.build.result }}" != "success" ] && echo "  • Docker build"
          [ "${{ needs.deploy-production.result }}" != "success" ] && echo "  • Kubernetes deployment"
          exit 1
        fi
